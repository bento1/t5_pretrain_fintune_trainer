import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

SOS_TOKEN = dataset.SOS_TOKEN
EOS_TOKEN = dataset.EOS_TOKEN

class Encoder(nn.Module):
    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):
        super(Encoder, self).__init__()
        
        # ë‹¨ì–´ ì‚¬ì „ì˜ ê°œìˆ˜ ì§€ì •
        self.num_vocabs = num_vocabs
        self.embedding_dim = embedding_dim
        self.hidden_size = hidden_size
        
        # ì„ë² ë”© ë ˆì´ì–´ ì •ì˜ (number of vocabs, embedding dimension)
        self.embedding = nn.Embedding(num_vocabs, embedding_dim)
        # GRU (embedding dimension)
        self.gru = nn.GRU(embedding_dim, 
                        hidden_size, 
                        num_layers=num_layers, 
                        bidirectional=False, 
                        batch_first=True,
                        )
        
    def forward(self, x, hidden):
        x = self.embedding(x).view(1, 1, -1)
        # x: (1, 1, embedding_dim)
        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        output, hidden = self.gru(x, hidden)
        # output: (batch_size, sequence_length, hidden_size(32) x bidirectional(1))
        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        return output, hidden
    
    def init_hidden(self, device):
        # hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32)) ë¡œ ì´ˆê¸°í™”
        return torch.zeros(1, 1, self.hidden_size, device=device)

class AttentionDecoder(nn.Module):
    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p=0.1, max_length=MAX_LENGTH):
        super(AttentionDecoder, self).__init__()
        self.hidden_size = hidden_size
        self.max_length = max_length

        self.embedding = nn.Embedding(num_vocabs, embedding_dim)
        self.attn = nn.Linear(hidden_size + embedding_dim , max_length)
        self.attn_combine = nn.Linear(hidden_size + embedding_dim, hidden_size)
        self.dropout = nn.Dropout(dropout_p)
        self.gru = nn.GRU(hidden_size, hidden_size)
        self.out = nn.Linear(hidden_size, num_vocabs)

    def forward(self, x, hidden, encoder_outputs):
        # x: (1, 1) 1ê°œì˜ í† í°
        embedded = self.embedding(x).view(1, 1, -1)
        # embedded: (1, 1, 1)
        embedded = self.dropout(embedded)

        
        # embedded[0]: (1, embedding_dim)
        # hidden[0]: (1, hidden_size)
        attn_in = torch.cat((embedded[0], hidden[0]), 1)
        # attn_in: (1, embedding_dim + hidden_size)
                            
        attn = self.attn(attn_in)
        # attn: (1, max_length)

        attn_weights = F.softmax(attn)
        # attn_weights: (1, max_length)
        
        # (1, 1, max_length), (1, max_length, hidden_size)
        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))
        # attn_applied: (1, 1, hidden_size)

        # embedded[0]: (1, embedding_dim)
        # attn_applied[0]: (1, hidden_size)
        output = torch.cat((embedded[0], attn_applied[0]), 1)
        # output: (1, embedding_dim + hidden_size)
        
        output = self.attn_combine(output)
        # output: (1, hidden_size)
        output = output.unsqueeze(0)
        # output: (1, 1, hidden_size)

        output = F.relu(output)
        # output: (1, 1, hidden_size)
        
        # output: (1, 1, hidden_size)
        # hidden: (1, 1, hidden_size)
        output, hidden = self.gru(output, hidden)
        # output: (1, 1, hidden_size)
        # hidden: (1, 1, hidden_size)
        
        # output[0]: (1, hidden_size)
        output = self.out(output[0])
        # output: (1, number of vocabs)
        
        # output[0]: (number of vocabs)
        # hidden: (1, 1, hidden_size)
        # attn_weights: (1, max_length)
        return output[0], hidden, attn_weights

    def initHidden(self, device):
        # (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        return torch.zeros(1, 1, self.hidden_size, device=device)
    


# í›ˆë ¨ì‹œ training loss ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ util í•¨ìˆ˜
def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()
    # ì£¼ê¸°ì ì¸ ê°„ê²©ì— ì´ locatorê°€ tickì„ ì„¤ì •
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)
    plt.title('Losses over training')
    plt.show()
    
# í›ˆë ¨ì‹œ ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ util í•¨ìˆ˜
def as_minutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return f'{int(m)}m {int(s)}s'

# í›ˆë ¨ì‹œ ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ util í•¨ìˆ˜
def time_since(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return f'{as_minutes(s)} (remaining: {as_minutes(rs)})'


def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, 
        decoder_optimizer, criterion, device, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):
    
    # Encoderì˜ hidden_state ì´ˆê¸°í™”
    encoder_hidden = encoder.init_hidden(device=device)

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    # input_length: ì…ë ¥ ë¬¸ì¥ì˜ ê¸¸ì´
    # target_length: ì¶œë ¥ ë¬¸ì¥ì˜ ê¸¸ì´
    input_length = input_tensor.size(0)
    target_length = target_tensor.size(0)

    # Encoderì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë‹´ì„ tensor
    # (ë¬¸ì¥ì˜ max_length, encoderì˜ hidden_size)
    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)

    loss = 0

    for ei in range(input_length):
        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)
        # Encoderì˜ ì¶œë ¥ì„ encoder_outputs[ei] ì— ì €ì¥
        # encoder_output[0, 0]: (hidden_size,)
        encoder_outputs[ei] = encoder_output[0, 0]

    # Decoderì˜ ì²« í† í°ì€ SOS_TOKEN
    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)

    # Encoderì˜ ë§ˆì§€ë§‰ hidden stateë¥¼ Decoderì˜ ì´ˆê¸° hidden stateë¡œ ì§€ì •
    decoder_hidden = encoder_hidden

    # teacher forcing ì ìš© ì—¬ë¶€ í™•ë¥ ë¡œ ê²°ì •
    # teacher forcing ì´ë€: ì •ë‹µì¹˜ë¥¼ ë‹¤ìŒ RNN Cellì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ê²½ìš°. ìˆ˜ë ´ì†ë„ê°€ ë¹ ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜, ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False

    for di in range(target_length):
        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)

        # loss ê³„ì‚°
        loss += criterion(decoder_output.view(1, -1), target_tensor[di])

        if use_teacher_forcing:
            # teacher forcing ì ìš©: ì •ë‹µ ê°’ ì…ë ¥
            decoder_input = target_tensor[di]
        else:
            # í™•ë¥ , ì¸ë±ìŠ¤
            topv, topi = decoder_output.topk(1)
            # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì£¼ì…í•  ë””ì½”ë” ìµœì¢… í† í° ê²°ì •
            decoder_input = topi.squeeze().detach()  # ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ë¶€ë¶„ì„ íˆìŠ¤í† ë¦¬ì—ì„œ ë¶„ë¦¬

        # EOS_TOKEN ì´ë©´ ì¢…ë£Œ
        if decoder_input.item() == EOS_TOKEN:
            break

    loss.backward()
    
    encoder_optimizer.step()
    decoder_optimizer.step()

    return loss.item() / target_length


ğŸ”¥ì•Œë¦¼ğŸ”¥
â‘  í…Œë””ë…¸íŠ¸ ìœ íŠœë¸Œ - êµ¬ê²½í•˜ëŸ¬ ê°€ê¸°!
â‘¡ LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ ë°”ë¡œê°€ê¸° ğŸ‘€
â‘¢ ë­ì²´ì¸ ë…¸íŠ¸ ë¬´ë£Œ ì „ìì±…(wikidocs) ë°”ë¡œê°€ê¸° ğŸ™Œ
â‘£ RAG ë¹„ë²•ë…¸íŠ¸ LangChain ê°•ì˜ì˜¤í”ˆ ë°”ë¡œê°€ê¸° ğŸ™Œ
â‘¤ ì„œìš¸ëŒ€ PyTorch ë”¥ëŸ¬ë‹ ê°•ì˜ ë°”ë¡œê°€ê¸° ğŸ™Œ

[pytorch] Seq2Seq with Attention êµ¬í˜„ ë° í•œ ì¤„ì”© ì½”ë“œ ì„¤ëª…
 2023ë…„ 03ì›” 22ì¼   17 ë¶„ ì†Œìš”
 ëª©ì°¨
ëª¨ë“ˆ imports
1. ë°ì´í„° ì „ì²˜ë¦¬
1-1. í•œê¸€ ì •ê·œí™”
1-2. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°
1-3. ë‹¨ì–´ ì‚¬ì „ ìƒì„±
1-4. ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ í´ë˜ìŠ¤í™”
2. Encoder
3. Attention ì´ ì ìš©ëœ Decoder
4. Training
5. Evaluation
6. Attention ê°€ì¤‘ì¹˜ ì‹œê°í™”
ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” Attention ë©”ì¹´ë‹ˆì¦˜ì´ ì ìš©ëœ Seq2Seq ëª¨ë¸ì„ pytorchë¡œ êµ¬í˜„í•˜ê³ , ì½”ë“œ í•œ ì¤„ì”© ì§ì ‘ shapeë¥¼ ì°ì–´ë³´ê³  í™•ì¸í•˜ë©´ì„œ êµ¬í˜„ëœ ì½”ë“œ í†µí•´ ë™ì‘ ì›ë¦¬ì™€ Attention êµ¬ì¡°ë¥¼ ì´í•´í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ í™œìš©í•œ í•œê¸€ ì±—ë´‡ ë°ì´í„°ëŠ” songys/Chatbot_data ë¥¼ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

Attentionì„ ì ìš©í•˜ì§€ ì•Šì€ Seq2Seq ëª¨ë¸ êµ¬ì¡°ì™€ ë¹„êµ í•´ ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤. [pytorch] Seq2Seq ìœ¼ë¡œ ì±—ë´‡ ë§Œë“¤ê¸° (ì½”ë“œ êµ¬í˜„) ê¸€ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”.


ë…¼ë¬¸ ë§í¬

Neural Machine Translation by Jointly Learning to Align and Translate(2014)
ì°¸ê³ 

ê¸°ì´ˆë¶€í„° ì‹œì‘í•˜ëŠ” NLP: SEQUENCE TO SEQUENCE ë„¤íŠ¸ì›Œí¬ì™€ ATTENTIONì„ ì´ìš©í•œ ë²ˆì—­
songys/Chatbot_data

ì‹¤ìŠµì½”ë“œ



ëª¨ë“ˆ importsPermalink
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import random
import warnings
import time
import math

# Unicode warning ì œê±° (í°íŠ¸ ê´€ë ¨ ê²½ê³ ë©”ì‹œì§€)
plt.rcParams['axes.unicode_minus']=False
# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = "NanumGothic"

warnings.filterwarnings('ignore')

data_dir = 'data'

df = pd.read_csv(os.path.join(data_dir, 'ChatbotData.csv'))
df
Q	A	label
0	12ì‹œ ë•¡!	í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.	0
1	1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´	ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.	0
2	3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤	ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .	0
3	3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤	ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .	0
4	PPL ì‹¬í•˜ë„¤	ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .	0
...	...	...	...
11818	í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.	í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !	2
11819	í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.	í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.	2
11820	í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.	ì„¤ë œê² ì–´ìš”.	2
11821	í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?	ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.	2
11822	í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´	ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.	2
11823 rows Ã— 3 columns

question = df['Q']
answer = df['A']
question[:5]
0             12ì‹œ ë•¡!
1        1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´
2       3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤
3    3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤
4            PPL ì‹¬í•˜ë„¤
Name: Q, dtype: object
answer[:5]
0     í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.
1      ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.
2    ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .
3    ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .
4     ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .
Name: A, dtype: object
1. ë°ì´í„° ì „ì²˜ë¦¬Permalink
1-1. í•œê¸€ ì •ê·œí™”Permalink
import re

# í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±, ?!.,ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¬¸ì ì œê±°
korean_pattern = r'[^ ?,.!A-Za-z0-9ê°€-í£+]'

# íŒ¨í„´ ì»´íŒŒì¼
normalizer = re.compile(korean_pattern)
normalizer
re.compile(r'[^ ?,.!A-Za-z0-9ê°€-í£+]', re.UNICODE)
print(f'ìˆ˜ì • ì „: {question[10]}')
print(f'ìˆ˜ì • í›„: {normalizer.sub("", question[10])}')
ìˆ˜ì • ì „: SNSë³´ë©´ ë‚˜ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µí•´ë³´ì—¬
ìˆ˜ì • í›„: SNSë³´ë©´ ë‚˜ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µí•´ë³´ì—¬
print(f'ìˆ˜ì • ì „: {answer[10]}')
print(f'ìˆ˜ì • í›„: {normalizer.sub("", answer[10])}')
ìˆ˜ì • ì „: ìë‘í•˜ëŠ” ìë¦¬ë‹ˆê¹Œìš”.
ìˆ˜ì • í›„: ìë‘í•˜ëŠ” ìë¦¬ë‹ˆê¹Œìš”.
def normalize(sentence):
    return normalizer.sub("", sentence)

normalize(question[10])
'SNSë³´ë©´ ë‚˜ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µí•´ë³´ì—¬'
1-2. í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°Permalink
from konlpy.tag import Mecab, Okt

# í˜•íƒœì†Œ ë¶„ì„ê¸°
mecab = Mecab()
okt = Okt()
# mecab
mecab.morphs(normalize(question[10]))
['SNS', 'ë³´', 'ë©´', 'ë‚˜', 'ë§Œ', 'ë¹¼', 'ê³ ', 'ë‹¤', 'í–‰ë³µ', 'í•´', 'ë³´ì—¬']
# okt
okt.morphs(normalize(answer[10]))
['ìë‘', 'í•˜ëŠ”', 'ìë¦¬', 'ë‹ˆê¹Œ', 'ìš”', '.']
# í•œê¸€ ì „ì²˜ë¦¬ë¥¼ í•¨ìˆ˜í™”
def clean_text(sentence, tagger):
    sentence = normalize(sentence)
    sentence = tagger.morphs(sentence)
    sentence = ' '.join(sentence)
    sentence = sentence.lower()
    return sentence
# í•œê¸€
clean_text(question[10], okt)
'sns ë³´ë©´ ë‚˜ ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µ í•´ë³´ì—¬'
# ì˜ì–´
clean_text(answer[10], okt)
'ìë‘ í•˜ëŠ” ìë¦¬ ë‹ˆê¹Œ ìš” .'
len(question), len(answer)
(11823, 11823)
questions = [clean_text(sent, okt) for sent in question.values[:1000]]
answers = [clean_text(sent, okt) for sent in answer.values[:1000]]
questions[:5]
['12ì‹œ ë•¡ !', '1 ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´', '3 ë°• 4ì¼ ë†€ëŸ¬ ê°€ê³  ì‹¶ë‹¤', '3 ë°• 4ì¼ ì •ë„ ë†€ëŸ¬ ê°€ê³  ì‹¶ë‹¤', 'ppl ì‹¬í•˜ë„¤']
answers[:5]
['í•˜ë£¨ ê°€ ë˜ ê°€ë„¤ìš” .',
 'ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .',
 'ì—¬í–‰ ì€ ì–¸ì œë‚˜ ì¢‹ì£  .',
 'ì—¬í–‰ ì€ ì–¸ì œë‚˜ ì¢‹ì£  .',
 'ëˆˆì‚´ ì´ ì°Œí‘¸ë ¤ì§€ì£  .']
1-3. ë‹¨ì–´ ì‚¬ì „ ìƒì„±Permalink
import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
from torch.utils.data.dataset import Dataset

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device
device(type='cuda', index=0)
class WordVocab():
    def __init__(self):
        SOS_TOKEN = 0
        EOS_TOKEN = 1
        UNKNOWN_TOKEN = 2
        
        self.unknown_token = UNKNOWN_TOKEN
        
        # ê° í† í° ë³„ word count
        self.word2count = {}
        
        # word -> idx
        self.word2index = {
            '<SOS>': SOS_TOKEN, 
            '<EOS>': EOS_TOKEN,
            '<UKN>': UNKNOWN_TOKEN,
        }

        # idx -> word
        self.index2word = {
            SOS_TOKEN: '<SOS>', 
            EOS_TOKEN: '<EOS>', 
            UNKNOWN_TOKEN: '<UKN>',
        }
        
        # total word counts
        self.n_words = 3  # SOS, EOS, UNKNOWN í¬í•¨

    def add_sentence(self, sentence):
        for word in sentence.split(' '):
            self.add_word(word)

    def add_word(self, word):
        if word not in self.word2index:
            self.word2index[word] = self.n_words
            self.word2count[word] = 1
            self.index2word[self.n_words] = word
            self.n_words += 1
        else:
            self.word2count[word] += 1
    
    def word_to_index(self, word):
        if word in self.word2index:
            return self.word2index[word]
        else:
            return self.unknown_token
    
    def index_to_word(self, idx):
        return self.index2word[idx]
questions[10]
'sns ë³´ë©´ ë‚˜ ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µ í•´ë³´ì—¬'
print(f'ì›ë¬¸: {questions[10]}')
wordvocab = WordVocab()
wordvocab.add_sentence(questions[10])
print('==='*10)
print('ë‹¨ì–´ì‚¬ì „')
print(wordvocab.word2index)
ì›ë¬¸: sns ë³´ë©´ ë‚˜ ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µ í•´ë³´ì—¬
==============================
ë‹¨ì–´ì‚¬ì „
{'<SOS>': 0, '<EOS>': 1, '<UKN>': 2, 'sns': 3, 'ë³´ë©´': 4, 'ë‚˜': 5, 'ë§Œ': 6, 'ë¹¼ê³ ': 7, 'ë‹¤': 8, 'í–‰ë³µ': 9, 'í•´ë³´ì—¬': 10}
1-4. ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ í´ë˜ìŠ¤í™”Permalink
ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ì •ê·œí™” ë° ì „ì²˜ë¦¬, í† í°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.

ë‹¨ì–´ ì‚¬ì „ì„ ìƒì„±í•˜ê³  ì´ì— ë”°ë¼, ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

from konlpy.tag import Mecab, Okt


class QADataset():
    def __init__(self, csv_path, min_length=3, max_length=25):
        data_dir = 'data'
        
        # TOKEN ì •ì˜
        self.SOS_TOKEN = 0 # SOS í† í°
        self.EOS_TOKEN = 1 # EOS í† í°
        
        self.tagger = Okt()   # í˜•íƒœì†Œ ë¶„ì„ê¸°
        self.max_length = max_length # í•œ ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ ì§€ì •
        
        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(os.path.join(data_dir, csv_path))
        
        # í•œê¸€ ì •ê·œí™”
        korean_pattern = r'[^ ?,.!A-Za-z0-9ê°€-í£+]'
        self.normalizer = re.compile(korean_pattern)
        
        # src: ì§ˆì˜, tgt: ë‹µë³€
        src_clean = []
        tgt_clean = []
        
        # ë‹¨ì–´ ì‚¬ì „ ìƒì„±
        wordvocab = WordVocab()
        
        for _, row in df.iterrows():
            src = row['Q']
            tgt = row['A']
            
            # í•œê¸€ ì „ì²˜ë¦¬
            src = self.clean_text(src)
            tgt = self.clean_text(tgt)
            
            if len(src.split()) > min_length and len(tgt.split()) > min_length:
                # ìµœì†Œ ê¸¸ì´ë¥¼ ë„˜ì–´ê°€ëŠ” ë¬¸ì¥ì˜ ë‹¨ì–´ë§Œ ì¶”ê°€
                wordvocab.add_sentence(src)
                wordvocab.add_sentence(tgt)
                src_clean.append(src)
                tgt_clean.append(tgt)            
        
        self.srcs = src_clean
        self.tgts = tgt_clean
        self.wordvocab = wordvocab

    
    def normalize(self, sentence):
        # ì •ê·œí‘œí˜„ì‹ì— ë”°ë¥¸ í•œê¸€ ì •ê·œí™”
        return self.normalizer.sub("", sentence)

    def clean_text(self, sentence):
        # í•œê¸€ ì •ê·œí™”
        sentence = self.normalize(sentence)
        # í˜•íƒœì†Œ ì²˜ë¦¬
        sentence = self.tagger.morphs(sentence)
        sentence = ' '.join(sentence)
        sentence = sentence.lower()
        return sentence
    
    def texts_to_sequences(self, sentence):
        # ë¬¸ì¥ -> ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
        sequences = [self.wordvocab.word_to_index(w) for w in sentence.split()]
        # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´ -1 ê¹Œì§€ ìŠ¬ë¼ì´ì‹±
        sequences = sequences[:self.max_length-1]
        # ë§¨ ë§ˆì§€ë§‰ì— EOS TOKEN ì¶”ê°€
        sequences.append(self.EOS_TOKEN)
        return sequences
    
    def sequences_to_texts(self, sequences):
        # ì‹œí€€ìŠ¤ -> ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        sentences = [self.wordvocab.index_to_word(s.item()) for s in sequences]
        return ' '.join(sentences)

    
    def __getitem__(self, idx):
        inputs = self.srcs[idx]
        inputs_sequences = self.texts_to_sequences(inputs)
        
        outputs = self.tgts[idx]
        outputs_sequences = self.texts_to_sequences(outputs)
        
        return torch.tensor(inputs_sequences).view(-1, 1), torch.tensor(outputs_sequences).view(-1, 1)
    
    def __len__(self):
        return len(self.srcs)
# í•œ ë¬¸ì¥ì˜ ìµœëŒ€ ë‹¨ì–´ê¸¸ì´ë¥¼ 25ë¡œ ì„¤ì •
MAX_LENGTH = 25

dataset = QADataset('ChatbotData.csv', min_length=3, max_length=MAX_LENGTH)
# 3ë²ˆ index ë°ì´í„°ì…‹ ì¡°íšŒ
# ê²°ê³¼: x(ì…ë ¥ ë°ì´í„°), y(ì¶œë ¥ ë°ì´í„°)
dataset[3]
(tensor([[22],
         [23],
         [24],
         [25],
         [ 1]]),
 tensor([[26],
         [27],
         [28],
         [29],
         [30],
         [31],
         [10],
         [ 1]]))
x, y = dataset[3]

# ì‹œí€€ìŠ¤ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
print(dataset.sequences_to_texts(x))
print(dataset.sequences_to_texts(y))
sd ì¹´ë“œ ì•ˆ ë¼ <EOS>
ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš” . <EOS>
2. EncoderPermalink
seq2seq w attn-Encoder

class Encoder(nn.Module):
    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):
        super(Encoder, self).__init__()
        
        # ë‹¨ì–´ ì‚¬ì „ì˜ ê°œìˆ˜ ì§€ì •
        self.num_vocabs = num_vocabs
        self.embedding_dim = embedding_dim
        self.hidden_size = hidden_size
        
        # ì„ë² ë”© ë ˆì´ì–´ ì •ì˜ (number of vocabs, embedding dimension)
        self.embedding = nn.Embedding(num_vocabs, embedding_dim)
        # GRU (embedding dimension)
        self.gru = nn.GRU(embedding_dim, 
                          hidden_size, 
                          num_layers=num_layers, 
                          bidirectional=False, 
                          batch_first=True,
                         )
        
    def forward(self, x, hidden):
        x = self.embedding(x).view(1, 1, -1)
        # x: (1, 1, embedding_dim)
        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        output, hidden = self.gru(x, hidden)
        # output: (batch_size, sequence_length, hidden_size(32) x bidirectional(1))
        # hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        return output, hidden
    
    def init_hidden(self, device):
        # hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32)) ë¡œ ì´ˆê¸°í™”
        return torch.zeros(1, 1, self.hidden_size, device=device)
Embedding Layer
# x, y ì¶”ì¶œ
x, y = dataset[0]
embedding_dim = 20 # ì„ë² ë”© ì°¨ì›
embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)

embedded = embedding(x[0])

print(x.shape)
print(embedded.view(1, 1, -1).shape)
# input:  (sequence_length, 1)
# output: (1, 1, embedding_dim)
torch.Size([5, 1])
torch.Size([1, 1, 20])
GRU Layer
embedding_dim = 20 # ì„ë² ë”© ì°¨ì›
hidden_size = 32   # GRU hidden_size

gru = nn.GRU(embedding_dim, 
             hidden_size, 
             num_layers=1, 
             bidirectional=False)

o, h = gru(embedded.view(1, 1, -1))

print(o.shape)
# output      : (batch_size, sequence_length, hidden_size(32) x bidirectional(1))
print(h.shape)
# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
torch.Size([1, 1, 32])
torch.Size([1, 1, 32])
Encoder
NUM_VOCABS = dataset.wordvocab.n_words
print(f'number of vocabs: {NUM_VOCABS}')
number of vocabs: 10548
# Encoder ì •ì˜
encoder = Encoder(NUM_VOCABS, 
                  hidden_size=32, 
                  embedding_dim=20, 
                  num_layers=1)
# Encoder hidden_state ì´ˆê¸°í™”
encoder.init_hidden(device=device).shape
torch.Size([1, 1, 32])
# Encoderì— x í†µê³¼ í›„ output, hidden_size ì˜ shape í™•ì¸
encoder_out, encoder_hidden = encoder(x[0], torch.zeros_like(encoder.init_hidden(device='cpu')))

print(encoder_out.shape)
print(encoder_hidden.shape)
# output      : (batch_size, sequence_length, hidden_size(32) x bidirectional(1))
# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
torch.Size([1, 1, 32])
torch.Size([1, 1, 32])
3. Attention ì´ ì ìš©ëœ DecoderPermalink
Seq2Seq-Attn-Decoder

class AttentionDecoder(nn.Module):
    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p=0.1, max_length=MAX_LENGTH):
        super(AttentionDecoder, self).__init__()
        self.hidden_size = hidden_size
        self.max_length = max_length

        self.embedding = nn.Embedding(num_vocabs, embedding_dim)
        self.attn = nn.Linear(hidden_size + embedding_dim , max_length)
        self.attn_combine = nn.Linear(hidden_size + embedding_dim, hidden_size)
        self.dropout = nn.Dropout(dropout_p)
        self.gru = nn.GRU(hidden_size, hidden_size)
        self.out = nn.Linear(hidden_size, num_vocabs)

    def forward(self, x, hidden, encoder_outputs):
        # x: (1, 1) 1ê°œì˜ í† í°
        embedded = self.embedding(x).view(1, 1, -1)
        # embedded: (1, 1, 1)
        embedded = self.dropout(embedded)

        
        # embedded[0]: (1, embedding_dim)
        # hidden[0]: (1, hidden_size)
        attn_in = torch.cat((embedded[0], hidden[0]), 1)
        # attn_in: (1, embedding_dim + hidden_size)
                            
        attn = self.attn(attn_in)
        # attn: (1, max_length)
                         
        attn_weights = F.softmax(attn)
        # attn_weights: (1, max_length)
        
        # (1, 1, max_length), (1, max_length, hidden_size)
        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))
        # attn_applied: (1, 1, hidden_size)

        # embedded[0]: (1, embedding_dim)
        # attn_applied[0]: (1, hidden_size)
        output = torch.cat((embedded[0], attn_applied[0]), 1)
        # output: (1, embedding_dim + hidden_size)
        
        output = self.attn_combine(output)
        # output: (1, hidden_size)
        output = output.unsqueeze(0)
        # output: (1, 1, hidden_size)

        output = F.relu(output)
        # output: (1, 1, hidden_size)
        
        # output: (1, 1, hidden_size)
        # hidden: (1, 1, hidden_size)
        output, hidden = self.gru(output, hidden)
        # output: (1, 1, hidden_size)
        # hidden: (1, 1, hidden_size)
        
        # output[0]: (1, hidden_size)
        output = self.out(output[0])
        # output: (1, number of vocabs)
        
        # output[0]: (number of vocabs)
        # hidden: (1, 1, hidden_size)
        # attn_weights: (1, max_length)
        return output[0], hidden, attn_weights

    def initHidden(self, device):
        # (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))
        return torch.zeros(1, 1, self.hidden_size, device=device)
# ë””ì½”ë” ë¬¸ì¥ì˜ ê¸¸ì´ê°€ 12 ë‹¨ì–´ë¼ê³  ê°€ì •í•œ ê²½ìš°
x = torch.abs(torch.randn(size=(12, 1)).long())
x.shape
torch.Size([12, 1])
ë””ì½”ë”ì˜ ë‹¨ì–´ 1ê°œì— ëŒ€í•œ Embedding
embedding_dim = 20
embedding = nn.Embedding(wordvocab.n_words, embedding_dim)

# Decoderì˜ ë‹¨ì–´ 1ê°œ: x[0]ë¥¼ ì…ë ¥ìœ¼ë¡œ ê°€ì§
embedded = embedding(x[0])
print(embedded.shape)
# (1, 20)

embedded = embedded.view(1, 1, -1)
# (1, 1, 20)
print(embedded.shape)
torch.Size([1, 20])
torch.Size([1, 1, 20])
ë“œë¡­ì•„ì›ƒ ì ìš©
# dropout ì ìš©
dropout = nn.Dropout(0.1)
embedded = dropout(embedded)
embedded.shape
torch.Size([1, 1, 20])
ë””ì½”ë”ì˜ ì²« ë²ˆì§¸ ë‹¨ì–´ëŠ” Encoder hidden_stateë¥¼ ì‚¬ìš©

ë‘ ë²ˆì§¸ ë‹¨ì–´ë¶€í„°ëŠ” ì´ì „ ë‹¨ê³„ì˜ Decoder hidden_stateë¥¼ ì‚¬ìš©

ë””ì½”ë“œì˜ í˜„ì¬ ì…ë ¥ Embedding + (Encoder hidden_state or Decoder ì´ì „ ë‹¨ê³„ì˜ hidden_state)ë¥¼ concat

ê²°ê³¼ëŠ” (1, E + H)

# ì²« ë‹¨ì–´ëŠ” encoder_hidden ì‚¬ìš©, ë‘ ë²ˆì§¸ ë‹¨ì–´ë¶€í„°ëŠ” decoder_hidden ì‚¬ìš©
# encoder_hidden.shape == decoder_hidden.shape ê°™ì•„ì•¼ í•¨
# hidden.shape: (1, 1, H)
hidden = encoder_hidden
print(hidden[0].shape)
print(embedded[0].shape)
torch.Size([1, 32])
torch.Size([1, 20])
# ë””ì½”ë“œì˜ í˜„ì¬ ì…ë ¥ Embedding + (Encoder hidden_state or Decoder ì´ì „ ë‹¨ê³„ì˜ hidden_state)ë¥¼ concat
context = torch.cat((embedded[0], hidden[0]), 1)
context.shape
torch.Size([1, 52])
attention ìƒì„±

FC ë ˆì´ì–´: (1, E+H) -> (1, MAX_LENGTH)

# (1, E+H) -> (1, MAX_LENGTH)
fc = nn.Linear(hidden_size+embedding_dim, MAX_LENGTH)
attn = fc(context)
print(attn.shape)
torch.Size([1, 25])
attn_weights = F.softmax(attn, dim=1)
# attn weights: (1, MAX_LENGTH)
print('ë³€ê²½ ì „:', attn_weights.shape)
# (1, MAX_LENGTH) -> (1, 1, MAX_LENGTH)
attn_weights = attn_weights.unsqueeze(0)
print('ë³€ê²½ í›„:', attn_weights.shape)
ë³€ê²½ ì „: torch.Size([1, 25])
ë³€ê²½ í›„: torch.Size([1, 1, 25])
# Encoderì˜ ì‹œí€€ìŠ¤ ë³„ Hê°€ ëª¨ë‘ ì±„ì›Œì§„ Matrix
encoder_outputs = torch.zeros(MAX_LENGTH, hidden_size)
# (MAX_LENGTH, H)
print('ë³€ê²½ ì „:', encoder_outputs.shape)
encoder_outputs = encoder_outputs.unsqueeze(0)
# (1, MAX_LENGTH, H)
print('ë³€ê²½ í›„', encoder_outputs.shape)
ë³€ê²½ ì „: torch.Size([25, 32])
ë³€ê²½ í›„ torch.Size([1, 25, 32])
attention weights: í˜„ì¬ì˜ ë””ì½”ë” ì…ë ¥ (1ê°œ ë‹¨ì–´)ì™€ ì´ì „ ë‹¨ê³„ì˜ hidden_state ì‚¬ì´ì—ì„œ êµ¬í•œ Energy

encoder outputs: ì¸ì½”ë”ì˜ ì „ì²´ ë¬¸ì¥ ì¶œë ¥ (MAX_LENGTH, hidden_size)ë¡œ ì´ë£¨ì–´ì§.

attention weights ì™€ encoder outputs ê°„ì˜ Attention BMMì„ ì‚°ì¶œ

# BMM: (1, 1, MAX_LENGTH) x (1, MAX_LENGTH, H) => (1, 1, H)
# BMM ì ìš© í›„: (1, 1, H)
attn_applied = torch.bmm(attn_weights, encoder_outputs)
attn_applied.shape
torch.Size([1, 1, 32])
ë””ì½”ë”ì˜ í˜„ì¬ ì…ë ¥ (1ê°œ ë‹¨ì–´)ì™€ Attention ê°’ì„ concat

(1, E) + (1, H) = (1, E+H)

FC: (1, E+H) -> (1, H)

output = torch.cat((embedded[0], attn_applied[0]), 1)
# (1, E+H)
print('concat ê²°ê³¼ : ', output.shape)
fc = nn.Linear(hidden_size+embedding_dim, hidden_size)
output = fc(output)
# (1, H)
print('FC í†µê³¼ í›„   : ', output.shape)
# GRU ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•˜ì—¬ (1, H) -> (1, 1, H)
output = output.unsqueeze(0)
print('unsqueeze í›„: ', output.shape)
concat ê²°ê³¼ :  torch.Size([1, 52])
FC í†µê³¼ í›„   :  torch.Size([1, 32])
unsqueeze í›„:  torch.Size([1, 1, 32])
outputì„ ReLU í†µê³¼

GRUì˜ ì…ë ¥ìœ¼ë¡œ output, hidden ì£¼ì…

output: (1, 1, H), hidden: (1, 1, H)

output = F.relu(output)
gru = nn.GRU(hidden_size, hidden_size)
output, hidden = gru(output, hidden)
output.shape, hidden.shape
(torch.Size([1, 1, 32]), torch.Size([1, 1, 32]))
output: (1, 1, 32) -> (1, 32)

outputì„ ìµœì¢… ì¶œë ¥ìœ¼ë¡œ ë³€ê²½: (1, number of vocabs)

# (1, H) -> (1, number of vocabs)
out = nn.Linear(hidden_size, dataset.wordvocab.n_words)
decoder_out = out(output[0])
# (1, number of vocabs)
decoder_out.shape
torch.Size([1, 10548])
attention ë””ì½”ë” ì…ì¶œë ¥ í™•ì¸
# ì…ë ¥ ë¬¸ì¥ì˜ ê¸¸ì´ê°€ 12 ë‹¨ì–´ë¼ê³  ê°€ì •í•œ ê²½ìš°
# x: 12ê°œì˜ í† í°ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì…ë ¥ ë¬¸ì¥ì´ë¼ê³  ê°€ì •
x = torch.abs(torch.randn(size=(12, 1)).long())
x.shape
torch.Size([12, 1])
encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size)
# (max_length, hidden_size)
encoder_outputs.shape
torch.Size([25, 32])
# (1, 1, hidden_size)
encoder_hidden.shape
torch.Size([1, 1, 32])
# Attentionì´ ì ìš©ëœ ë””ì½”ë” ìƒì„±
decoder = AttentionDecoder(num_vocabs=NUM_VOCABS, 
                           hidden_size=32, 
                           embedding_dim=20, 
                           dropout_p=0.1, 
                           max_length=MAX_LENGTH)
# y[0]: ë””ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” 1ê°œ í† í°
decoder_out, decoder_hidden, attn_weights = decoder(y[0], encoder_hidden, encoder_outputs)
# decoder_out: (number of vocabs)
# decoder_hidden: (1, 1, hidden_size)
# attn_weights: (1, max_length)
decoder_out.shape, decoder_hidden.shape, attn_weights.shape
(torch.Size([10548]), torch.Size([1, 1, 32]), torch.Size([1, 25]))
4. TrainingPermalink
SOS_TOKEN = dataset.SOS_TOKEN
EOS_TOKEN = dataset.EOS_TOKEN
# í›ˆë ¨ì‹œ training loss ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ util í•¨ìˆ˜
def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()
    # ì£¼ê¸°ì ì¸ ê°„ê²©ì— ì´ locatorê°€ tickì„ ì„¤ì •
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)
    plt.title('Losses over training')
    plt.show()
    
# í›ˆë ¨ì‹œ ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ util í•¨ìˆ˜
def as_minutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return f'{int(m)}m {int(s)}s'

# í›ˆë ¨ì‹œ ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ util í•¨ìˆ˜
def time_since(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return f'{as_minutes(s)} (remaining: {as_minutes(rs)})'
def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, 
          decoder_optimizer, criterion, device, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):
    
    # Encoderì˜ hidden_state ì´ˆê¸°í™”
    encoder_hidden = encoder.init_hidden(device=device)

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    # input_length: ì…ë ¥ ë¬¸ì¥ì˜ ê¸¸ì´
    # target_length: ì¶œë ¥ ë¬¸ì¥ì˜ ê¸¸ì´
    input_length = input_tensor.size(0)
    target_length = target_tensor.size(0)

    # Encoderì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë‹´ì„ tensor
    # (ë¬¸ì¥ì˜ max_length, encoderì˜ hidden_size)
    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)

    loss = 0

    for ei in range(input_length):
        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)
        # Encoderì˜ ì¶œë ¥ì„ encoder_outputs[ei] ì— ì €ì¥
        # encoder_output[0, 0]: (hidden_size,)
        encoder_outputs[ei] = encoder_output[0, 0]

    # Decoderì˜ ì²« í† í°ì€ SOS_TOKEN
    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)

    # Encoderì˜ ë§ˆì§€ë§‰ hidden stateë¥¼ Decoderì˜ ì´ˆê¸° hidden stateë¡œ ì§€ì •
    decoder_hidden = encoder_hidden

    # teacher forcing ì ìš© ì—¬ë¶€ í™•ë¥ ë¡œ ê²°ì •
    # teacher forcing ì´ë€: ì •ë‹µì¹˜ë¥¼ ë‹¤ìŒ RNN Cellì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ê²½ìš°. ìˆ˜ë ´ì†ë„ê°€ ë¹ ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜, ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False

    for di in range(target_length):
        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)

        # loss ê³„ì‚°
        loss += criterion(decoder_output.view(1, -1), target_tensor[di])

        if use_teacher_forcing:
            # teacher forcing ì ìš©: ì •ë‹µ ê°’ ì…ë ¥
            decoder_input = target_tensor[di]
        else:
            # í™•ë¥ , ì¸ë±ìŠ¤
            topv, topi = decoder_output.topk(1)
            # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì£¼ì…í•  ë””ì½”ë” ìµœì¢… í† í° ê²°ì •
            decoder_input = topi.squeeze().detach()  # ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ë¶€ë¶„ì„ íˆìŠ¤í† ë¦¬ì—ì„œ ë¶„ë¦¬

        # EOS_TOKEN ì´ë©´ ì¢…ë£Œ
        if decoder_input.item() == EOS_TOKEN:
            break

    loss.backward()
    
    encoder_optimizer.step()
    decoder_optimizer.step()

    return loss.item() / target_length
def train_iterations(encoder, decoder, n_iters, dataset, device, print_every=1000, plot_every=100, learning_rate=0.001):
    start = time.time()
    plot_losses = []
    print_loss_total = 0  # print_every ë§ˆë‹¤ ì´ˆê¸°í™”
    plot_loss_total = 0  # plot_every ë§ˆë‹¤ ì´ˆê¸°í™”

    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)
    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)
    
    # ëœë¤ ìƒ˜í”Œë§ëœ ë°ì´í„°ì…‹ ìƒì„±
    training_pairs = [dataset[random.randint(0, len(dataset)-1)] for i in range(n_iters)]
    
    # Loss Function ì •ì˜
    criterion = nn.CrossEntropyLoss()

    # n_iters ë§Œí¼ training ì‹œì‘
    for iter in range(1, n_iters + 1):
        # ë¬¸ì¥ pair
        training_pair = training_pairs[iter - 1]        
        # ì…ë ¥ ë¬¸ì¥
        input_tensor = training_pair[0]
        # ì¶œë ¥ ë¬¸ì¥
        target_tensor = training_pair[1]
        
        input_tensor = input_tensor.to(device)
        target_tensor = target_tensor.to(device)

        # í›ˆë ¨
        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, 
                     decoder_optimizer, criterion, device)
        
        print_loss_total += loss
        plot_loss_total += loss

        # print_every ë§ˆë‹¤ loss ì¶œë ¥
        if iter % print_every == 0:
            print_loss_avg = print_loss_total / print_every
            print_loss_total = 0
            print(f'{time_since(start, iter/n_iters)} iter: {iter} ({iter/n_iters*100:.1f}%), loss: {print_loss_avg:.4f}')

        # plot_every ë§ˆë‹¤ loss ì‹œê°í™”
        if iter % plot_every == 0:
            plot_loss_avg = plot_loss_total / plot_every
            plot_losses.append(plot_loss_avg)
            plot_loss_total = 0

    showPlot(plot_losses)


def evaluate(encoder, decoder, input_tensor, dataset, device, max_length=MAX_LENGTH):
    # Eval ëª¨ë“œ ì„¤ì •
    encoder.eval()
    decoder.eval()
    
    with torch.no_grad():
        input_length = input_tensor.size(0)
        # Encoderì˜ hidden state ì´ˆê¸°í™”
        encoder_hidden = encoder.init_hidden(device=device)

        # encoder_outputsëŠ” Encoderë¥¼ í†µê³¼í•œ ë¬¸ì¥ì˜ ì¶œë ¥
        # (max_length, hidden_size)
        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)

        # Encoder ì— ì…ë ¥ ë¬¸ì ì£¼ì… í›„ encoder_outputs ìƒì„±
        for ei in range(input_length):
            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)
            encoder_outputs[ei] += encoder_output[0, 0]

        # Decoderì˜ ì²« ë²ˆì§¸ ì…ë ¥ìœ¼ë¡œ SOS_TOKEN ì…ë ¥(SOS_TOKEN=0)
        decoder_input = torch.tensor([[0]], device=device)

        # Decoderì˜ ì²« ë²ˆì§¸ hidden stateëŠ” Encoderì˜ ë§ˆì§€ë§‰ hidden state ì‚¬ìš©
        decoder_hidden = encoder_hidden

        decoded_words = []
        decoder_attentions = torch.zeros(max_length, max_length)

        for di in range(max_length):
            # 1ê°œì˜ Decoder ì…ë ¥ í† í°ì„ í†µê³¼
            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)
            
            # Attention ì‹œê°í™”ë¥¼ ìœ„í•œ tensor ì €ì¥
            decoder_attentions[di] = decoder_attention.data

            # ì¶œë ¥ í† í° ì˜ˆì¸¡
            topv, topi = decoder_output.data.topk(1)

            # EOS_TOKENì´ë©´ ì¢…ë£Œ
            if topi.item() == dataset.EOS_TOKEN:
                decoded_words.append('<EOS>')
                break
            else:
                # ì¶œë ¥ ë¬¸ì¥ì— í† í° ì‹œí€€ìŠ¤(index)ë¥¼ ë‹¨ì–´(word)ë¡œ ë³€í™˜í•œ í›„ ì €ì¥
                decoded_words.append(dataset.wordvocab.index_to_word(topi.item()))

            # decoder_inputì€ ë‹¤ìŒ í† í° ì˜ˆì¸¡ì‹œ ì…ë ¥ ê°’
            # decoder_input: (hidden_size,)
            decoder_input = topi.squeeze().detach()

        return decoded_words, decoder_attentions[:di + 1]
    
def evaluate_randomly(encoder, decoder, dataset, device, n=10):
    for i in range(n):
        # ëœë¤ ìƒ˜í”Œë§
        x, y = random.choice(dataset)
        # ì…ë ¥ ë¬¸ì¥, ì¶œë ¥ ë¬¸ì¥ (Ground Truth)
        print('>', dataset.sequences_to_texts(x))
        print('=', dataset.sequences_to_texts(y))

        # ì˜ˆì¸¡
        output_words, attentions = evaluate(encoder, decoder, x.to(device), dataset, device)
        output_sentence = ' '.join(output_words)
        
        # ì˜ˆì¸¡ ë¬¸ì¥ ì¶œë ¥
        print('<', output_sentence)
        print('')

# Attention ì‹œê°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜
def show_attention(input_sentence, output_words, attentions):
    # colorbarë¡œ ê·¸ë¦¼ ì„¤ì •
    fig = plt.figure()
    ax = fig.add_subplot(111)
    cax = ax.matshow(attentions.numpy(), cmap='bone')
    fig.colorbar(cax)

    # ì¶• ì„¤ì •
    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)
    ax.set_yticklabels([''] + output_words)

    # ë§¤ í‹±ë§ˆë‹¤ ë¼ë²¨ ë³´ì—¬ì£¼ê¸°
    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))

    plt.show()


def evaluate_and_show_attention(encoder, decoder, input_sentence, dataset, device):
    output_words, attentions = evaluate(encoder, decoder, input_sentence.to(device), dataset, device)
    input_sentence = dataset.sequences_to_texts(input_sentence)
    output_words = ' '.join(output_words)
    print('input =', input_sentence)
    print('output =', output_words)
    show_attention(input_sentence, output_words.split(), attentions)